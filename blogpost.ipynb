{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "${KERNEL_SPEC_DISPLAY_NAME}",
      "language": "${KERNEL_SPEC_LANGUAGE}",
      "name": "${KERNEL_SPEC_NAME}"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [
          "#Reproducing ESPCN\n",
          "\n",
          "In this notebook we reproduce 91 generated images from the paper **Real-Time Single Image and Video Super-Resolution \n",
          "Using an Efficient Sub-Pixel Convolutional Neural Network**. The code has been created following the paper with gaps \n",
          "filled in by ourselves.\n",
          "The paper presents a convulutional neural network capable of real-time Super-Resolution (SR).\n",
          "They designed a CNN architecture where the feature maps are extracted in the Low-Resolution(LR) space, \n",
          "and introducing an efficient sub-pixel convolution layer which learns an array of upscaling filters to upscale\n",
          "the final LR feature maps into the High-Resolution(HR) output.\n",
          "\n",
          "---\n",
          "### SRCNN\n",
          "Recovers SR output image from an upscaled and interpolated version of LR image. \n",
          "Uses bicubic interpolation (as a special case of the deconvolution layer) to upscale image.\n",
          "Deconvolution layer a.k.a. Transposed convolution layer:\n",
          "_insert image_\n",
          "\n",
          "\n",
          "### ESPCN\n",
          "First apply a  layer CNN directly to LR image, then apply a sub-pixel convolution layer that upscales the LR feature \n",
          "maps to produce the SR output image. (to avoid upscaling LR before feeding it into the network)\n",
          "_insert image_\n",
          "For a network composed of L layers, the first L−1 layers can be described as follows:\n",
          "$f^1(\\boldsymbol{I}^{LR};W_1, b_1)= \\phi (W_1 \\ast \\boldsymbol{I}^{LR}+b_1)$\n",
          "$f^l(\\boldsymbol{I}^{LR};W_{1:l}, b_{1:l})= \\phi (W_1 \\ast f^{l-1}(\\boldsymbol{I}^{LR})+b_l)$\n",
          "Where $W_l , b_l , l \\in (1, L - 1)$ are learnable network weights and biases respectively.  \n",
          "$W_l$ is a 2D convolution tensor of size $n_{l-1} \\times n_l \\times k_l \\times k_l$ , where $n_l$ is the number of \n",
          "features at layer $l$, $n_0 = C$, and $k_l$ is the filter size at layer $l$. \n",
          "The biases $b_l$ are vectors of length $n_l$ . The nonlinearity function (or activation function) $\\phi$ is applied \n",
          "element-wise and is fixed. The last layer $f^L$ has to convert the LR feature maps to a HR image $\\boldsymble{I}^{SR}$.\n",
          "\n",
          "---\n",
          "\n",
          "## Experiment Setup \n",
          "\n",
          "Input = H x W x C\n",
          "Output = rH x rW x C\n",
          "\n",
          "Apply l layer CNN directly to Low Resolution (LR)\n",
          "Apply sub-pixel convolution layer upscaling LR feature maps\n",
          "\n",
          "Each layer except the last:\n",
          "$f^1(\\boldsymbol{I}^{LR};W_1, b_1)= \\phi (W_1 \\ast \\boldsymbol{I}^{LR}+b_1)$\n",
          "$f^l(\\boldsymbol{I}^{LR};W_{1:l}, b_{1:l})= \\phi (W_1 \\ast f^{l-1}(\\boldsymbol{I}^{LR})+b_l)$\n",
          "\n",
          "W & b learnable parameters\n",
          "W is a 2D convolution tensor of size n_(l-1) x n_l  x k_l x k_l\n",
          "    n_l is the amount of features of layer l, n_0 = C, k_l is the filter size at l\n",
          "    biases are of length n_l\n",
          "    activation function is fixed and element-wise\n",
          "\n",
          "Last layer converts LR to HR\n",
          "\n",
          "Efficient sub-pixel convolution layer: (biggest addition)\n",
          "Convolution with stride 1/r over LR with filter W_s of size k_s and weight spacing 1/r\n",
          "Weights between pixels are not activated and do not need to be calculated\n",
          "The number of activation patterns is exactly r^2.\n",
          "Each pattern has at most ceil(k_s/r)^2 weights\n",
          "Patterns are periodically activated during convolution of the filter depending on the subpixel location mod(x, r), mod(y,r), where x and y are the output pixel coordinates in HR.\n",
          "Solution for mod(k_s, r) = 0\n",
          "Last layer: note NO ACTIVATION\n",
          " $$I^{SR} = f^L(I^{LR}) = PS(W_L * f^{L-1}(I^{LR})+b_L)$$\n",
          "PS is a periodic shuffling operator (sort of mapping)\n",
          "_formule naar latex_\n",
          "W_L has shape n_(L-1) x r^2C x k_L x k_L\n",
          "k_L = k_s/r and mod(k_s, r) = 0\n",
          "\n",
          "Loss function: (mean squared error)\n",
          "_formule naar latex_\n",
          "Preshuffle training data avoiding the use of PS\n",
          "\n",
          "---\n",
          "# The model\n",
          "\n",
          "Everything we need is imported\n",
          "_imports block_\n",
          "\n",
          "---\n",
          "\n",
          "hyperparameters to set\n",
          "\n",
          "_hyperparameters block_"
        ],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "blogpost.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlyY-v4OEIDw",
        "colab_type": "text"
      },
      "source": [
        "#Reproducing ESPCN\n",
        "\n",
        "In this notebook we reproduce 91 generated images from the paper **Real-Time Single Image and Video Super-Resolution \n",
        "Using an Efficient Sub-Pixel Convolutional Neural Network**. The code has been created following the paper with gaps \n",
        "filled in by ourselves.\n",
        "The paper presents a convulutional neural network capable of real-time Super-Resolution (SR).\n",
        "They designed a CNN architecture where the feature maps are extracted in the Low-Resolution(LR) space, \n",
        "and introducing an efficient sub-pixel convolution layer which learns an array of upscaling filters to upscale\n",
        "the final LR feature maps into the High-Resolution(HR) output.\n",
        "A researcher would like a reproduction of this to test on his high-res dataset.\n",
        "\n",
        "---\n",
        "### SRCNN\n",
        "Recovers SR output image from an upscaled and interpolated version of LR image. \n",
        "Uses bicubic interpolation (as a special case of the deconvolution layer) to upscale image.\n",
        "Deconvolution layer a.k.a. Transposed convolution layer: \\\\\n",
        "_insert image_\n",
        "\n",
        "\n",
        "### ESPCN\n",
        "First apply a  layer CNN directly to LR image, then apply a sub-pixel convolution layer that upscales the LR feature \n",
        "maps to produce the SR output image. (to avoid upscaling LR before feeding it into the network) \\\\\n",
        "_insert image_ \\\\\n",
        "For a network composed of L layers, the first L−1 layers can be described as follows: \\\\\n",
        "$f^1(\\boldsymbol{I}^{LR};W_1, b_1)= \\phi (W_1 \\ast \\boldsymbol{I}^{LR}+b_1)$ \\\\\n",
        "$f^l(\\boldsymbol{I}^{LR};W_{1:l}, b_{1:l})= \\phi (W_1 \\ast f^{l-1}(\\boldsymbol{I}^{LR})+b_l)$ \\\\\n",
        "Where $W_l , b_l , l \\in (1, L - 1)$ are learnable network weights and biases respectively.  \n",
        "$W_l$ is a 2D convolution tensor of size $n_{l-1} \\times n_l \\times k_l \\times k_l$ , where $n_l$ is the number of \n",
        "features at layer $l$, $n_0 = C$, and $k_l$ is the filter size at layer $l$. \n",
        "The biases $b_l$ are vectors of length $n_l$ . The nonlinearity function (or activation function) $\\phi$ is applied \n",
        "element-wise and is fixed. The last layer $f^L$ has to convert the LR feature maps to a HR image $\\boldsymbol{I}^{SR}$.\n",
        "\n",
        "---\n",
        "\n",
        "## Experiment Setup \n",
        "\n",
        "Input = H x W x C\n",
        "Output = rH x rW x C\n",
        "\n",
        "Apply l layer CNN directly to Low Resolution (LR)\n",
        "Apply sub-pixel convolution layer upscaling LR feature maps\n",
        "\n",
        "Each layer except the last: \\\\\n",
        "$f^1(\\boldsymbol{I}^{LR};W_1, b_1)= \\phi (W_1 \\ast \\boldsymbol{I}^{LR}+b_1)$ \\\\\n",
        "$f^l(\\boldsymbol{I}^{LR};W_{1:l}, b_{1:l})= \\phi (W_1 \\ast f^{l-1}(\\boldsymbol{I}^{LR})+b_l)$\n",
        "\n",
        "W & b learnable parameters\n",
        "\n",
        "W is a 2D convolution tensor of size n_(l-1) x n_l  x k_l x k_l\n",
        "\n",
        "n_l is the amount of features of layer l, n_0 = C, k_l is the filter size at l\n",
        "\n",
        "biases are of length n_l\n",
        "\n",
        "activation function is fixed and element-wise\n",
        "\n",
        "Last layer converts LR to HR\n",
        "\n",
        "Efficient sub-pixel convolution layer: (biggest addition)\n",
        "\n",
        "Convolution with stride 1/r over LR with filter W_s of size k_s and weight spacing 1/r \\\\\n",
        "Weights between pixels are not activated and do not need to be calculated \\\\\n",
        "The number of activation patterns is exactly r^2. \\\\\n",
        "Each pattern has at most ceil(k_s/r)^2 weights \\\\\n",
        "Patterns are periodically activated during convolution of the filter depending on the subpixel location mod(x, r), mod(y,r), where x and y are the output pixel coordinates in HR. \\\\\n",
        "Solution for mod(k_s, r) = 0 \\\\\n",
        "Last layer: note NO ACTIVATION \\\\\n",
        " $I^{SR} = f^L(I^{LR}) = PS(W_L * f^{L-1}(I^{LR})+b_L)$ \\\\\n",
        "PS is a periodic shuffling operator (sort of mapping) \\\\\n",
        "_formule naar latex_ \\\\\n",
        "W_L has shape n_(L-1) x r^2C x k_L x k_L \\\\\n",
        "k_L = k_s/r and mod(k_s, r) = 0\n",
        "\n",
        "Loss function: (mean squared error) \\\\\n",
        "_formule naar latex_ \\\\\n",
        "Preshuffle training data avoiding the use of PS\n",
        "\n",
        "---\n",
        "# The model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw7N_3dGGdtk",
        "colab_type": "text"
      },
      "source": [
        "Everything we need is imported and help methods are created\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuwZj7xuGAix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_imports block_\n",
        "\n",
        "_block met imshow enzo_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YE5tg_8GkFF",
        "colab_type": "text"
      },
      "source": [
        "hyperparameters to set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmxbwLXHGMwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_hyperparameters block_\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6GNLWCmGnz9",
        "colab_type": "text"
      },
      "source": [
        "Data en downsample uitleg\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKgQGMS9GM8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_downsample block_\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J017G3b9Grk6",
        "colab_type": "text"
      },
      "source": [
        "neural network uitleg\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-dbqVPjGNCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_net block_\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQYuI340GvRZ",
        "colab_type": "text"
      },
      "source": [
        "training uitleg\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UAB7-mzGM_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_training block_\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB69kyUtGzRF",
        "colab_type": "text"
      },
      "source": [
        "resultaten op een image\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE42YlokGM7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_resultaten block_\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYKfnMHWG3Ht",
        "colab_type": "text"
      },
      "source": [
        "resultaten op een video\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJqExq7cGM58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_block met video resultaten_\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orV0awMeG7GJ",
        "colab_type": "text"
      },
      "source": [
        "We succeeded in reproducing the 91 pictures and the high-res video from the researcher requesting this."
      ]
    }
  ]
}